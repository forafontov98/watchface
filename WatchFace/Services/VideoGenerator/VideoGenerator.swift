//
//  VideoGenerator.swift
//  GifToLive
//
//  Created by MacBook on 12.01.2021.
//

import UIKit
import AVFoundation

public class VideoGenerator: NSObject {
  
    // MARK: --------------------------------------------------------------- Singleton properties
  
    open class var current: VideoGenerator {
        struct Static {
            static var instance = VideoGenerator()
        }
    
        return Static.instance
    }

  
    // MARK: --------------------------------------------------------------- Public properties
  
    /// public property to set a multiple type video's background color
    public static var videoBackgroundColor: UIColor = UIColor.black
  
    /// public property to set a width to scale the image to before generating a video (used only with .single type video generation; preferred scale: 800/1200)
    public static var scaleWidth: CGFloat?
  
    /// public property to set the maximum length of a video
    public static var maxVideoLengthInSeconds: Double?
  
    /// public property to set the FPS of a video (from gif)
    public static var fpsValue: Int = 30

    /// public property to set the video duration when there is no audio
    public static var videoDurationInSeconds: Double = 0 {
        didSet {
            videoDurationInSeconds = Double(CMTime(seconds: videoDurationInSeconds, preferredTimescale: 1).seconds)
        }
    }
  
    // MARK: - Public methods
  
    // MARK: --------------------------------------------------------------- Generate video
  
    func generate(from imageData: Data, _ progress: @escaping ((Progress) -> Void), outcome: @escaping (Result<URL, Error>) -> Void) {

        let gifOptions = [
            kCGImageSourceShouldAllowFloat as String : true as NSNumber,
            kCGImageSourceCreateThumbnailWithTransform as String : true as NSNumber,
            kCGImageSourceCreateThumbnailFromImageAlways as String : true as NSNumber
            ] as CFDictionary

        guard let imageSource = CGImageSourceCreateWithData(imageData as CFData, gifOptions) else {
            debugPrint("Cannot create image source with data!")
            return
        }

        let framesCount = CGImageSourceGetCount(imageSource)
        var frameList = [UIImage]()

        for index in 0 ..< framesCount {

            if let cgImageRef = CGImageSourceCreateImageAtIndex(imageSource, index, nil) {
                let uiImageRef = UIImage(cgImage: cgImageRef)
                frameList.append(uiImageRef)
            }

        }

        generate(withImages: frameList,
                 progress,
                 outcome: outcome)
        
    }
    
    /**
     Public method to start a video generation
   
     - parameter progress: A block which will track the progress of the generation
     - parameter success:  A block which will be called after successful generation of video
     - parameter failure:  A blobk which will be called on a failure durring the generation of the video
     */
    func generate(withImages _images: [UIImage], _ progress: @escaping ((Progress) -> Void), outcome: @escaping (Result<URL, Error>) -> Void) {
    
    let dispatchQueueGenerate = DispatchQueue(label: "generate", qos: .background)
    
    dispatchQueueGenerate.async { [weak self] in
      
        VideoGenerator.current.setup(withImages: _images)
              
        /// define the input and output size of the video which will be generated by taking the first image's size
        if let firstImage = VideoGenerator.current.images.first {
            VideoGenerator.current.minSize = firstImage.size
        }
      
        let inputSize = VideoGenerator.current.minSize
        let outputSize = VideoGenerator.current.minSize
      
        self?.getTempVideoFileUrl { (videoOutputURL) in
            do {
                /// try to create an asset writer for videos pointing to the video url
                try VideoGenerator.current.videoWriter = AVAssetWriter(outputURL: videoOutputURL, fileType: AVFileType.mov)
            } catch {
                VideoGenerator.current.videoWriter = nil
                DispatchQueue.main.async {
                    outcome(.failure(error))
                }
            }
        
        /// check if the writer is instantiated successfully
        if let videoWriter = VideoGenerator.current.videoWriter {
          
          /// create the basic video settings
        let videoSettings: [String : AnyObject] = [
            AVVideoCodecKey  : AVVideoCodecType.h264 as AnyObject,
            AVVideoWidthKey  : outputSize.width as AnyObject,
            AVVideoHeightKey : outputSize.height as AnyObject,
        ]
          
        /// create a video writter input
        let videoWriterInput = AVAssetWriterInput(mediaType: AVMediaType.video, outputSettings: videoSettings)
          
        /// create setting for the pixel buffer
        let sourceBufferAttributes: [String : AnyObject] = [
            (kCVPixelBufferPixelFormatTypeKey as String): Int(kCVPixelFormatType_32ARGB) as AnyObject,
            (kCVPixelBufferWidthKey as String): Float(inputSize.width) as AnyObject,
            (kCVPixelBufferHeightKey as String):  Float(inputSize.height) as AnyObject,
            (kCVPixelBufferCGImageCompatibilityKey as String): NSNumber(value: true),
            (kCVPixelBufferCGBitmapContextCompatibilityKey as String): NSNumber(value: true)
        ]
          
        /// create pixel buffer for the input writter and the pixel buffer settings
        let pixelBufferAdaptor = AVAssetWriterInputPixelBufferAdaptor(
            assetWriterInput: videoWriterInput,
            sourcePixelBufferAttributes: sourceBufferAttributes)
          
        /// check if an input can be added to the asset
        assert(videoWriter.canAdd(videoWriterInput))
          
        /// add the input writter to the video asset
        videoWriter.add(videoWriterInput)
          
        /// check if a write session can be executed
        if videoWriter.startWriting() {
            
            /// if it is possible set the start time of the session (current at the begining)
            videoWriter.startSession(atSourceTime: CMTime.zero)
            
            /// check that the pixel buffer pool has been created
            assert(pixelBufferAdaptor.pixelBufferPool != nil)
            
            /// create/access separate queue for the generation process
            let media_queue = DispatchQueue(label: "mediaInputQueue", attributes: [])
            
            /// start video generation on a separate queue
            videoWriterInput.requestMediaDataWhenReady(on: media_queue, using: { () -> Void in
              
            /// set up preliminary properties for the image count, frame count and the video elapsed time
            let numImages = VideoGenerator.current.images.count
            var frameCount = 0
            var elapsedTime: Double = 0
              
            let currentProgress = Progress(totalUnitCount: Int64(VideoGenerator.current.images.count))
              
            var nextStartTimeForFrame: CMTime! = CMTime(seconds: 0, preferredTimescale: 1)
              
            /// if the input writer is ready and we have not yet used all imaged
            while (videoWriterInput.isReadyForMoreMediaData && frameCount < numImages) {
                
                let imageForVideo = VideoGenerator.current.images[frameCount]
                nextStartTimeForFrame = frameCount == 0 ? CMTime(seconds: 0, preferredTimescale: 600) : CMTime(seconds: Double(elapsedTime), preferredTimescale: 600)
                
                elapsedTime += 1.0 / Double(VideoGenerator.fpsValue)
                
                /// append the image to the pixel buffer at the right start time
                if !VideoGenerator.current.appendPixelBufferForImage(imageForVideo, pixelBufferAdaptor: pixelBufferAdaptor, presentationTime: nextStartTimeForFrame) {
                    DispatchQueue.main.async {
                        VideoGenerator.current.videoWriter = nil
                        outcome(.failure(VideoGeneratorError(error: .kFailedToAppendPixelBufferError)))
                    }
                }
                
                // increise the frame count
                frameCount += 1
                
                currentProgress.completedUnitCount = Int64(frameCount)
                
                // after each successful append of an image track the current progress
                progress(currentProgress)
            }
              
            // after all images are appended the writting shoul be marked as finished
            videoWriterInput.markAsFinished()
              
            if let _maxLength = VideoGenerator.maxVideoLengthInSeconds {
                videoWriter.endSession(atSourceTime: CMTime(seconds: _maxLength, preferredTimescale: 1))
            }
              
            // the completion is made with a completion handler which will return the url of the generated video or an error
            videoWriter.finishWriting { () -> Void in
                if let documentsPath = NSSearchPathForDirectoriesInDomains(.documentDirectory, .userDomainMask, true).first {
                    let newPath = URL(fileURLWithPath: documentsPath).appendingPathComponent("processing.mov")
                    self?.deleteFile(pathURL: newPath, completion: {
                        try FileManager.default.moveItem(at: videoOutputURL, to: newPath)
                    })
                  
                    print("finished")
                    DispatchQueue.main.async {
                        outcome(.success(newPath))
                    }
                }
                
                VideoGenerator.current.videoWriter = nil
            }
        })
        } else {
            DispatchQueue.main.async {
                VideoGenerator.current.videoWriter = nil
                outcome(.failure(VideoGeneratorError(error: .kFailedToStartAssetWriterError)))
            }
        }
        
        } else {
            DispatchQueue.main.async {
                VideoGenerator.current.videoWriter = nil
                outcome(.failure(VideoGeneratorError(error: .kFailedToStartAssetWriterError)))
            }
        }
        }
    }
    
  }
  
    /**
    setup method of the class
     
    - parameter _images:     The images from which a video will be generated
    - parameter _duration: The duration of the movie which will be generated
    */
    fileprivate func setup(withImages _images: [UIImage]) {
        images = []
        duration = 0.0
        var datasImages = [Data?]()
      
        /// guard against missing images or audio
        guard !_images.isEmpty else {
            return
        }
      
        for _image in _images {
            let imageWidth = _image.size.width * 1.5
            let imageHeight = _image.size.height * 1.5
            
            autoreleasepool {
                if let imageData = _image.scaleImageToSize(
                    newSize: CGSize(width: imageWidth,
                                    height: imageHeight))?.pngData() {
                    
                        datasImages.append(imageData)
                }
            }
        }
        
        datasImages.forEach {
            if let imageData = $0, let image = UIImage(data: imageData, scale: UIScreen.main.scale) {
                self.images.append(image)
            }
        }
        
        datasImages.removeAll()

    }
    
    /// private property to store the images from which a video will be generated
    fileprivate var images: [UIImage] = []
    
    /// private property to store the duration of the generated video
    fileprivate var duration: Double! = 1.0
    
    /// private property to store a video asset writer (optional because the generation might fail)
    fileprivate var videoWriter: AVAssetWriter? {
      didSet {
        if videoWriter == nil {
          images.removeAll()
        }
      }
    }
    
    /// private property to store the minimum size for the video
    fileprivate var minSize = CGSize.zero
    
    /// private property to store the minimum duration for a single video
    fileprivate var minSingleVideoDuration: Double = 3.0
    
    /// Private method to delete the temp video file
    ///
    /// - Returns: the temp file url
    private func getTempVideoFileUrl(completion: @escaping (URL) -> ()) {
        DispatchQueue.main.async {
            if let documentsPath = NSSearchPathForDirectoriesInDomains(.documentDirectory, .userDomainMask, true).first {
                let testOutputURL = URL(fileURLWithPath: documentsPath).appendingPathComponent("test.mov")
                
                do {
                    if FileManager.default.fileExists(atPath: testOutputURL.path) {
                        try FileManager.default.removeItem(at: testOutputURL)
                    }
                } catch {
                    print(error.localizedDescription)
                }
          
                completion(testOutputURL)
            }
        }
    }
    
    /// Private method to delete a file
    ///
    /// - Parameters:
    ///   - pathURL: the file's path
    ///   - completion: a blick to handle completion
    private func deleteFile(pathURL: URL, completion: @escaping () throws -> ()) {
        DispatchQueue.main.async {
            do {
                if FileManager.default.fileExists(atPath: pathURL.path) {
                    try FileManager.default.removeItem(at: pathURL)
                }
            } catch {
                print(error.localizedDescription)
            }
        
            do {
                try completion()
            } catch {
                print(error.localizedDescription)
            }
        }
    }
    
    /**
     Private method to append pixels to a pixel buffer
     
     - parameter url:                The image which pixels will be appended to the pixel buffer
     - parameter pixelBufferAdaptor: The pixel buffer to which new pixels will be added
     - parameter presentationTime:   The duration of each frame of the video
     
     - returns: True or false depending on the action execution
     */
    private func appendPixelBufferForImage(_ image: UIImage, pixelBufferAdaptor: AVAssetWriterInputPixelBufferAdaptor, presentationTime: CMTime) -> Bool {
      
        /// at the beginning of the append the status is false
        var appendSucceeded = false
      
        /**
         *  The proccess of appending new pixels is put inside a autoreleasepool
         */
        autoreleasepool {
        
            // check posibilitty of creating a pixel buffer pool
            if let pixelBufferPool = pixelBufferAdaptor.pixelBufferPool {
          
                let pixelBufferPointer = UnsafeMutablePointer<CVPixelBuffer?>.allocate(capacity: MemoryLayout<CVPixelBuffer?>.size)
                let status: CVReturn = CVPixelBufferPoolCreatePixelBuffer(
                    kCFAllocatorDefault,
                    pixelBufferPool,
                    pixelBufferPointer
                )
          
                /// check if the memory of the pixel buffer pointer can be accessed and the creation status is 0
                if let pixelBuffer = pixelBufferPointer.pointee, status == 0 {
            
                    // if the condition is satisfied append the image pixels to the pixel buffer pool
                    fillPixelBufferFromImage(image, pixelBuffer: pixelBuffer)
            
                    // generate new append status
                    appendSucceeded = pixelBufferAdaptor.append(
                        pixelBuffer,
                        withPresentationTime: presentationTime
                    )
            
                    /**
                     *  Destroy the pixel buffer contains
                     */
                    pixelBufferPointer.deinitialize(count: 1)
                } else {
                    NSLog("error: Failed to allocate pixel buffer from pool")
                }
          
                /**
                 Destroy the pixel buffer pointer from the memory
                 */
                pixelBufferPointer.deallocate()
            }
        }
      
        return appendSucceeded
    }
    
    /**
     Private method to append image pixels to a pixel buffer
     
     - parameter image:       The image which pixels will be appented
     - parameter pixelBuffer: The pixel buffer (as memory) to which the image pixels will be appended
     */
    private func fillPixelBufferFromImage(_ image: UIImage, pixelBuffer: CVPixelBuffer) {
        // lock the buffer memoty so no one can access it during manipulation
        CVPixelBufferLockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: CVOptionFlags(0)))
      
        // get the pixel data from the address in the memory
        let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer)
      
        // create a color scheme
        let rgbColorSpace = CGColorSpaceCreateDeviceRGB()
      
        /// set the context size
        let contextSize = image.size
      
        // generate a context where the image will be drawn
        if let context = CGContext(
            data: pixelData,
            width: Int(contextSize.width),
            height: Int(contextSize.height),
            bitsPerComponent: 8,
            bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer),
            space: rgbColorSpace,
            bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue) {
        
                var imageHeight = image.size.height
                var imageWidth = image.size.width
        
                if Int(imageHeight) > context.height {
                    imageHeight = 16 * (CGFloat(context.height) / 16).rounded(.awayFromZero)
                } else if Int(imageWidth) > context.width {
                    imageWidth = 16 * (CGFloat(context.width) / 16).rounded(.awayFromZero)
                }
        
            let center = CGPoint(x: (minSize.width - imageWidth) / 2, y: (minSize.height - imageHeight) / 2)
        
            context.clear(CGRect(x: 0.0, y: 0.0, width: imageWidth, height: imageHeight))
        
            // set the context's background color
            context.setFillColor(VideoGenerator.videoBackgroundColor.cgColor)
            context.fill(CGRect(x: 0.0, y: 0.0, width: CGFloat(context.width), height: CGFloat(context.height)))
        
            context.concatenate(.identity)
        
            // draw the image in the context
        
            if let cgImage = image.cgImage {
                context.draw(cgImage, in: CGRect(x: center.x, y: center.y, width: imageWidth, height: imageHeight))
            }
        
            // unlock the buffer memory
            CVPixelBufferUnlockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: CVOptionFlags(0)))
        }
    }
}
